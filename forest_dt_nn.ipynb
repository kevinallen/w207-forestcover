{
 "metadata": {
  "name": "",
  "signature": "sha256:9e0e7397b5544783020f6e51d2c946549d55cd204dcf7f32035e10ed66c7ee94"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Forest Cover Prediction\n",
      "\n",
      "Neural Nets\n",
      "\n",
      "Rosalind Lee"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "# Familiar libraries.\n",
      "import numpy as np\n",
      "import time\n",
      "import csv\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn import tree\n",
      "\n",
      "# Take a moment to install Theano.  We will use it for building neural networks.\n",
      "import theano \n",
      "from theano import tensor as T\n",
      "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
      "print theano.config.device # We're using CPUs (for now)\n",
      "print theano.config.floatX # Should be 64 bit for CPUs\n",
      "\n",
      "np.random.seed(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cpu\n",
        "float64\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the feature names from the first row of the train data\n",
      "with open(\"train.csv\",\"r\") as f:\n",
      "    reader = csv.reader(f)\n",
      "    feature_names = reader.next()\n",
      "# read the train and test data\n",
      "train_data = np.loadtxt(open(\"train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
      "test_data = np.loadtxt(open(\"test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
      "\n",
      "# use pandas to read csv\n",
      "train = pd.read_csv('train.csv')\n",
      "\n",
      "# remove CoverType from the feature names and training data\n",
      "feature_names = feature_names[:-1]\n",
      "all_train, all_train_labels = train_data[:,:-1], train_data[:,-1]\n",
      "\n",
      "# shuffle the training data and divide into train and dev\n",
      "examples = all_train.shape[0]\n",
      "shuffle = np.random.permutation(np.arange(examples))\n",
      "all_train, all_train_labels = all_train[shuffle], all_train_labels[shuffle]\n",
      "train_data, train_labels = all_train[:.8*examples], all_train_labels[:.8*examples]\n",
      "dev_data, dev_labels = all_train[.8*examples:], all_train_labels[.8*examples:]\n",
      "\n",
      "# remove id\n",
      "train_data = train_data[:,1:]\n",
      "dev_data = dev_data[:,1:]\n",
      "\n",
      "numFeatures = train_data.shape[1]\n",
      "numTrainExamples = train_data.shape[0]\n",
      "numDevExamples = dev_data.shape[0]\n",
      "\n",
      "print 'There are %s features, %s training examples, %s dev examples' % \\\n",
      "    (numFeatures, numTrainExamples, numDevExamples)\n",
      "print 'The features are:'\n",
      "for feature in feature_names:\n",
      "    print '  ',feature\n",
      "    \n",
      "\n",
      "print dev_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 54 features, 12096 training examples, 3024 dev examples\n",
        "The features are:\n",
        "   Id\n",
        "   Elevation\n",
        "   Aspect\n",
        "   Slope\n",
        "   Horizontal_Distance_To_Hydrology\n",
        "   Vertical_Distance_To_Hydrology\n",
        "   Horizontal_Distance_To_Roadways\n",
        "   Hillshade_9am\n",
        "   Hillshade_Noon\n",
        "   Hillshade_3pm\n",
        "   Horizontal_Distance_To_Fire_Points\n",
        "   Wilderness_Area1\n",
        "   Wilderness_Area2\n",
        "   Wilderness_Area3\n",
        "   Wilderness_Area4\n",
        "   Soil_Type1\n",
        "   Soil_Type2\n",
        "   Soil_Type3\n",
        "   Soil_Type4\n",
        "   Soil_Type5\n",
        "   Soil_Type6\n",
        "   Soil_Type7\n",
        "   Soil_Type8\n",
        "   Soil_Type9\n",
        "   Soil_Type10\n",
        "   Soil_Type11\n",
        "   Soil_Type12\n",
        "   Soil_Type13\n",
        "   Soil_Type14\n",
        "   Soil_Type15\n",
        "   Soil_Type16\n",
        "   Soil_Type17\n",
        "   Soil_Type18\n",
        "   Soil_Type19\n",
        "   Soil_Type20\n",
        "   Soil_Type21\n",
        "   Soil_Type22\n",
        "   Soil_Type23\n",
        "   Soil_Type24\n",
        "   Soil_Type25\n",
        "   Soil_Type26\n",
        "   Soil_Type27\n",
        "   Soil_Type28\n",
        "   Soil_Type29\n",
        "   Soil_Type30\n",
        "   Soil_Type31\n",
        "   Soil_Type32\n",
        "   Soil_Type33\n",
        "   Soil_Type34\n",
        "   Soil_Type35\n",
        "   Soil_Type36\n",
        "   Soil_Type37\n",
        "   Soil_Type38\n",
        "   Soil_Type39\n",
        "   Soil_Type40\n",
        "[[  2.44200000e+03   3.02000000e+02   1.80000000e+01 ...,   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]\n",
        " [  3.33100000e+03   1.04000000e+02   9.00000000e+00 ...,   0.00000000e+00\n",
        "    1.00000000e+00   0.00000000e+00]\n",
        " [  2.32400000e+03   9.20000000e+01   2.40000000e+01 ...,   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]\n",
        " ..., \n",
        " [  3.51500000e+03   1.58000000e+02   2.70000000e+01 ...,   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]\n",
        " [  2.57500000e+03   8.00000000e+01   3.50000000e+01 ...,   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]\n",
        " [  2.73800000e+03   3.04000000e+02   9.00000000e+00 ...,   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# decision tree classifier gini\n",
      "clf = tree.DecisionTreeClassifier()\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(train_data, train_labels)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "# decision tree classifier entropy\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(train_data, train_labels)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "print clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "0.801587301587\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.804232804233\n",
        "[  5.52530393e-01   2.35081184e-02   1.51700130e-02   5.33441006e-02\n",
        "   2.54412554e-02   7.46059232e-02   4.49850452e-02   2.72773710e-02\n",
        "   2.28665573e-02   5.99033573e-02   2.54896305e-02   1.89554647e-03\n",
        "   1.70555444e-03   4.85838572e-03   4.78687503e-04   3.02303304e-03\n",
        "   1.04352218e-02   5.39565933e-03   1.42965810e-04   1.58193517e-03\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   8.76926735e-03\n",
        "   1.44603239e-03   2.36397208e-03   2.00165321e-03   3.68562743e-04\n",
        "   0.00000000e+00   4.40152864e-04   1.67136509e-03   1.42368412e-04\n",
        "   0.00000000e+00   1.55134275e-03   1.70805100e-04   1.08904570e-03\n",
        "   2.89104571e-03   9.55888487e-04   0.00000000e+00   2.48236011e-04\n",
        "   3.18513469e-04   0.00000000e+00   2.93586754e-03   1.92033894e-03\n",
        "   1.10759693e-03   2.65379621e-03   3.46995320e-03   0.00000000e+00\n",
        "   1.02465356e-03   0.00000000e+00   0.00000000e+00   2.26637816e-03\n",
        "   4.22404623e-03   1.33036342e-03]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use pandas to read csv\n",
      "data = pd.read_csv('train.csv')\n",
      "# shuffle = np.random.permutation(np.arange(data.shape[0]))\n",
      "# data = data[shuffle]\n",
      "train = data[:len(data)*1/2]\n",
      "dev = data[len(data)*1/2:]\n",
      "\n",
      "# bin the elevation\n",
      "elevations = list(np.arange(train.Elevation.min() + 100, train.Elevation.max(), 50))\n",
      "elevations.insert(0,-np.inf)\n",
      "elevations.append(np.inf)\n",
      "train['Elevation'] = pd.cut(train.Elevation, elevations, labels=False)\n",
      "dev['Elevation'] = pd.cut(dev.Elevation, elevations, labels=False)\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "# bin the aspect\n",
      "aspects = list(np.arange(train.Aspect.min() + 10, train.Aspect.max(), 5))\n",
      "aspects.insert(0,-np.inf)\n",
      "aspects.append(np.inf)\n",
      "train['Aspect'] = pd.cut(train.Aspect, aspects, labels=False)\n",
      "dev['Aspect'] = pd.cut(dev.Aspect, aspects, labels=False)\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "\n",
      "# bin the horiz distance to hydrology\n",
      "hdth = list(np.arange(train.Horizontal_Distance_To_Hydrology.min() + 10, train.Horizontal_Distance_To_Hydrology.max(), 50))\n",
      "hdth.insert(0,-np.inf)\n",
      "hdth.append(np.inf)\n",
      "train['Horizontal_Distance_To_Hydrology'] = pd.cut(train.Horizontal_Distance_To_Hydrology, hdth, labels=False)\n",
      "dev['Horizontal_Distance_To_Hydrology'] = pd.cut(dev.Horizontal_Distance_To_Hydrology, hdth, labels=False)\n",
      "\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "# bin the vertical distance to hydrology\n",
      "vdth = list(np.arange(train.Vertical_Distance_To_Hydrology.min() + 10, train.Vertical_Distance_To_Hydrology.max(), 50))\n",
      "vdth.insert(0,-np.inf)\n",
      "vdth.append(np.inf)\n",
      "train['Vertical_Distance_To_Hydrology'] = pd.cut(train.Vertical_Distance_To_Hydrology, vdth, labels=False)\n",
      "dev['Vertical_Distance_To_Hydrology'] = pd.cut(dev.Vertical_Distance_To_Hydrology, vdth, labels=False)\n",
      "\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "# bin the horiz distance to roadways\n",
      "hdtr = list(np.arange(train.Horizontal_Distance_To_Roadways.min() + 10, train.Horizontal_Distance_To_Roadways.max(), 50))\n",
      "hdtr.insert(0,-np.inf)\n",
      "hdtr.append(np.inf)\n",
      "train['Horizontal_Distance_To_Roadways'] = pd.cut(train.Horizontal_Distance_To_Roadways, hdtr, labels=False)\n",
      "dev['Horizontal_Distance_To_Roadways'] = pd.cut(dev.Horizontal_Distance_To_Roadways, hdtr, labels=False)\n",
      "\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
      "clf = clf.fit(train_data, train_labels)\n",
      "clf.predict(dev_data)\n",
      "print clf.score(dev_data,dev_labels)\n",
      "\n",
      "print train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.801256613757\n",
        "0.796626984127"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.794642857143"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.799272486772"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.794973544974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
        "0        1         13       9      3                                 5   \n",
        "1        2         13      10      2                                 5   \n",
        "2        3         17      26      9                                 6   \n",
        "3        4         17      29     18                                 5   \n",
        "4        5         13       7      2                                 3   \n",
        "5        6         13      25      6                                 6   \n",
        "6        7         13       7      7                                 6   \n",
        "7        8         13       8      4                                 5   \n",
        "8        9         14       7      9                                 5   \n",
        "9       10         13      10     10                                 5   \n",
        "10      11         13      39      4                                 4   \n",
        "11      12         19      29     11                                 8   \n",
        "12      13         16      25     22                                 3   \n",
        "13      14         13      41      7                                 3   \n",
        "14      15         11      30      4                                 2   \n",
        "15      16         11       9      7                                 1   \n",
        "16      17         13      50      1                                 3   \n",
        "17      18         12      13      7                                 2   \n",
        "18      19         11       0      4                                 2   \n",
        "19      20         11       6      5                                 2   \n",
        "20      21         11      13      9                                 1   \n",
        "21      22         19      40     17                                 5   \n",
        "22      23         17      21     23                                 4   \n",
        "23      24         11       9      8                                 3   \n",
        "24      25         11       3      9                                 3   \n",
        "25      26         11      25      6                                 0   \n",
        "26      27         11      31     10                                 1   \n",
        "27      28         20      28     16                                 7   \n",
        "28      29         17      25      1                                 5   \n",
        "29      30         16      22     24                                 3   \n",
        "...    ...        ...     ...    ...                               ...   \n",
        "7530  7531         13       6      9                                 5   \n",
        "7531  7532         13       9     20                                 4   \n",
        "7532  7533         12      66     18                                 4   \n",
        "7533  7534         30      13     11                                16   \n",
        "7534  7535         30      15      8                                15   \n",
        "7535  7536         29      21      7                                15   \n",
        "7536  7537         29      18     12                                14   \n",
        "7537  7538         18       2      6                                 9   \n",
        "7538  7539         18       4     21                                 7   \n",
        "7539  7540         18      10     18                                 6   \n",
        "7540  7541         18      11     21                                 5   \n",
        "7541  7542         29      58     13                                11   \n",
        "7542  7543         27       6     14                                 6   \n",
        "7543  7544         15       5      7                                10   \n",
        "7544  7545         14      29      7                                 0   \n",
        "7545  7546         15      16      8                                 3   \n",
        "7546  7547         14      18     11                                 7   \n",
        "7547  7548         13       8     22                                 4   \n",
        "7548  7549         12       5     17                                 4   \n",
        "7549  7550         12       8     13                                 4   \n",
        "7550  7551         11      11     21                                 1   \n",
        "7551  7552         11      23     19                                 1   \n",
        "7552  7553         12      66     19                                 5   \n",
        "7553  7554         28      18     23                                11   \n",
        "7554  7555         18      10     19                                 6   \n",
        "7555  7556         28       8     16                                12   \n",
        "7556  7557         27       6     13                                 9   \n",
        "7557  7558         24       5     12                                 3   \n",
        "7558  7559         20      12      6                                17   \n",
        "7559  7560         15       9      4                                 8   \n",
        "\n",
        "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
        "0                                  3                               10   \n",
        "1                                  3                                8   \n",
        "2                                  4                               64   \n",
        "3                                  5                               62   \n",
        "4                                  3                                8   \n",
        "5                                  3                                2   \n",
        "6                                  3                               13   \n",
        "7                                  3                               12   \n",
        "8                                  4                               14   \n",
        "9                                  3                               13   \n",
        "10                                 4                               15   \n",
        "11                                 3                              105   \n",
        "12                                 4                               65   \n",
        "13                                 4                               16   \n",
        "14                                 3                               14   \n",
        "15                                 3                               15   \n",
        "16                                 3                               12   \n",
        "17                                 3                               12   \n",
        "18                                 3                               14   \n",
        "19                                 3                               15   \n",
        "20                                 3                               16   \n",
        "21                                 4                              100   \n",
        "22                                 5                               67   \n",
        "23                                 3                               13   \n",
        "24                                 3                               15   \n",
        "25                                 3                               17   \n",
        "26                                 3                               17   \n",
        "27                                 3                              119   \n",
        "28                                 4                               74   \n",
        "29                                 4                               66   \n",
        "...                              ...                              ...   \n",
        "7530                               5                               29   \n",
        "7531                               4                               29   \n",
        "7532                               4                               14   \n",
        "7533                               6                               43   \n",
        "7534                               6                               41   \n",
        "7535                               5                               39   \n",
        "7536                               7                               37   \n",
        "7537                               7                               22   \n",
        "7538                               6                               24   \n",
        "7539                               6                               25   \n",
        "7540                               6                               26   \n",
        "7541                               5                               30   \n",
        "7542                               5                               71   \n",
        "7543                               5                               48   \n",
        "7544                               3                               39   \n",
        "7545                               3                               37   \n",
        "7546                               3                               35   \n",
        "7547                               4                               29   \n",
        "7548                               4                               28   \n",
        "7549                               4                               28   \n",
        "7550                               3                               27   \n",
        "7551                               3                               19   \n",
        "7552                               5                               13   \n",
        "7553                               6                               34   \n",
        "7554                               6                               25   \n",
        "7555                               3                               70   \n",
        "7556                               6                               71   \n",
        "7557                               3                               62   \n",
        "7558                               7                               51   \n",
        "7559                               3                               47   \n",
        "\n",
        "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm     ...      Soil_Type32  \\\n",
        "0               221             232            148     ...                0   \n",
        "1               220             235            151     ...                0   \n",
        "2               234             238            135     ...                0   \n",
        "3               238             238            122     ...                0   \n",
        "4               220             234            150     ...                0   \n",
        "5               230             237            140     ...                0   \n",
        "6               222             225            138     ...                0   \n",
        "7               222             230            144     ...                0   \n",
        "8               223             221            133     ...                0   \n",
        "9               228             219            124     ...                0   \n",
        "10              218             243            161     ...                0   \n",
        "11              234             240            136     ...                0   \n",
        "12              248             224             92     ...                0   \n",
        "13              213             247            170     ...                0   \n",
        "14              224             240            151     ...                0   \n",
        "15              224             225            137     ...                0   \n",
        "16              216             239            161     ...                0   \n",
        "17              228             227            133     ...                0   \n",
        "18              214             232            156     ...                0   \n",
        "19              220             228            144     ...                0   \n",
        "20              230             223            126     ...                0   \n",
        "21              206             253            179     ...                0   \n",
        "22              252             209             71     ...                0   \n",
        "23              225             222            130     ...                0   \n",
        "24              215             221            143     ...                0   \n",
        "25              229             237            142     ...                0   \n",
        "26              230             243            145     ...                0   \n",
        "27              240             236            120     ...                0   \n",
        "28              220             238            154     ...                0   \n",
        "29              253             210             71     ...                0   \n",
        "...             ...             ...            ...     ...              ...   \n",
        "7530            220             219            134     ...                0   \n",
        "7531            227             192             90     ...                0   \n",
        "7532            178             213            173     ...                0   \n",
        "7533            234             218            115     ...                0   \n",
        "7534            232             226            127     ...                0   \n",
        "7535            232             233            134     ...                0   \n",
        "7536            239             224            113     ...                0   \n",
        "7537            216             228            149     ...                1   \n",
        "7538            208             190            111     ...                0   \n",
        "7539            229             200             97     ...                0   \n",
        "7540            233             191             80     ...                0   \n",
        "7541            182             235            193     ...                0   \n",
        "7542            220             209            121     ...                0   \n",
        "7543            219             226            143     ...                1   \n",
        "7544            229             241            145     ...                0   \n",
        "7545            232             227            129     ...                0   \n",
        "7546            238             226            118     ...                0   \n",
        "7547            221             188             92     ...                0   \n",
        "7548            215             200            115     ...                0   \n",
        "7549            224             212            120     ...                0   \n",
        "7550            232             191             82     ...                0   \n",
        "7551            248             223             96     ...                0   \n",
        "7552            177             210            169     ...                0   \n",
        "7553            250             203             69     ...                0   \n",
        "7554            231             197             91     ...                0   \n",
        "7555            225             204            108     ...                0   \n",
        "7556            219             210            123     ...                0   \n",
        "7557            218             214            130     ...                0   \n",
        "7558            227             228            135     ...                0   \n",
        "7559            222             231            145     ...                1   \n",
        "\n",
        "      Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
        "0               0            0            0            0            0   \n",
        "1               0            0            0            0            0   \n",
        "2               0            0            0            0            0   \n",
        "3               0            0            0            0            0   \n",
        "4               0            0            0            0            0   \n",
        "5               0            0            0            0            0   \n",
        "6               0            0            0            0            0   \n",
        "7               0            0            0            0            0   \n",
        "8               0            0            0            0            0   \n",
        "9               0            0            0            0            0   \n",
        "10              0            0            0            0            0   \n",
        "11              0            0            0            0            0   \n",
        "12              0            0            0            0            0   \n",
        "13              0            0            0            0            0   \n",
        "14              0            0            0            0            0   \n",
        "15              0            0            0            0            0   \n",
        "16              0            0            0            0            0   \n",
        "17              0            0            0            0            0   \n",
        "18              0            0            0            0            0   \n",
        "19              0            0            0            0            0   \n",
        "20              0            0            0            0            0   \n",
        "21              0            0            0            0            0   \n",
        "22              0            0            0            0            0   \n",
        "23              0            0            0            0            0   \n",
        "24              0            0            0            0            0   \n",
        "25              0            0            0            0            0   \n",
        "26              0            0            0            0            0   \n",
        "27              0            0            0            0            0   \n",
        "28              0            0            0            0            0   \n",
        "29              0            0            0            0            0   \n",
        "...           ...          ...          ...          ...          ...   \n",
        "7530            0            0            0            0            0   \n",
        "7531            0            0            0            0            0   \n",
        "7532            0            0            0            0            0   \n",
        "7533            0            0            1            0            0   \n",
        "7534            0            0            1            0            0   \n",
        "7535            0            0            1            0            0   \n",
        "7536            0            0            1            0            0   \n",
        "7537            0            0            0            0            0   \n",
        "7538            0            0            0            0            0   \n",
        "7539            0            0            0            0            0   \n",
        "7540            0            0            0            0            0   \n",
        "7541            0            0            0            0            0   \n",
        "7542            0            0            0            0            0   \n",
        "7543            0            0            0            0            0   \n",
        "7544            0            0            0            0            0   \n",
        "7545            0            0            0            0            0   \n",
        "7546            0            0            0            0            0   \n",
        "7547            0            0            0            0            0   \n",
        "7548            0            0            0            0            0   \n",
        "7549            0            0            0            0            0   \n",
        "7550            0            0            0            0            0   \n",
        "7551            0            0            0            0            0   \n",
        "7552            0            0            0            0            0   \n",
        "7553            0            0            0            0            0   \n",
        "7554            0            0            0            0            0   \n",
        "7555            0            0            0            0            0   \n",
        "7556            0            0            0            0            0   \n",
        "7557            0            0            0            0            0   \n",
        "7558            0            0            0            0            0   \n",
        "7559            0            0            0            0            0   \n",
        "\n",
        "      Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
        "0               0            0            0           5  \n",
        "1               0            0            0           5  \n",
        "2               0            0            0           2  \n",
        "3               0            0            0           2  \n",
        "4               0            0            0           5  \n",
        "5               0            0            0           2  \n",
        "6               0            0            0           5  \n",
        "7               0            0            0           5  \n",
        "8               0            0            0           5  \n",
        "9               0            0            0           5  \n",
        "10              0            0            0           5  \n",
        "11              0            0            0           2  \n",
        "12              0            0            0           2  \n",
        "13              0            0            0           5  \n",
        "14              0            0            0           5  \n",
        "15              0            0            0           5  \n",
        "16              0            0            0           5  \n",
        "17              0            0            0           5  \n",
        "18              0            0            0           5  \n",
        "19              0            0            0           5  \n",
        "20              0            0            0           5  \n",
        "21              0            0            0           2  \n",
        "22              0            0            0           5  \n",
        "23              0            0            0           5  \n",
        "24              0            0            0           5  \n",
        "25              0            0            0           5  \n",
        "26              0            0            0           5  \n",
        "27              0            0            0           2  \n",
        "28              0            0            0           2  \n",
        "29              0            0            0           5  \n",
        "...           ...          ...          ...         ...  \n",
        "7530            0            0            0           6  \n",
        "7531            0            0            0           6  \n",
        "7532            0            0            0           6  \n",
        "7533            0            0            0           7  \n",
        "7534            0            0            0           7  \n",
        "7535            0            0            0           7  \n",
        "7536            0            0            0           7  \n",
        "7537            0            0            0           2  \n",
        "7538            0            0            0           5  \n",
        "7539            0            0            0           5  \n",
        "7540            0            0            0           5  \n",
        "7541            0            1            0           7  \n",
        "7542            0            0            0           7  \n",
        "7543            0            0            0           6  \n",
        "7544            0            0            0           3  \n",
        "7545            0            0            0           3  \n",
        "7546            0            0            0           3  \n",
        "7547            0            0            0           6  \n",
        "7548            0            0            0           6  \n",
        "7549            0            0            0           6  \n",
        "7550            0            0            0           6  \n",
        "7551            0            0            0           3  \n",
        "7552            0            0            0           6  \n",
        "7553            0            1            0           7  \n",
        "7554            0            0            0           5  \n",
        "7555            0            1            0           7  \n",
        "7556            0            1            0           7  \n",
        "7557            0            0            0           2  \n",
        "7558            0            0            0           1  \n",
        "7559            0            0            0           6  \n",
        "\n",
        "[7560 rows x 56 columns]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert labels into a set of binary variables, one for each class (sometimes called a 1-of-n encoding).  \n",
      "# This makes working with NNs easier: there will be one output node for each class.\n",
      "print train_labels\n",
      "def binarizeY(data):\n",
      "    binarized_data = np.zeros((data.size,7))\n",
      "    for j in range(0,data.size):\n",
      "        feature = data[j:j+1]\n",
      "        i = feature.astype(np.int64) \n",
      "        binarized_data[j,i-1]=1\n",
      "    return binarized_data\n",
      "train_labels_b = binarizeY(train_labels)\n",
      "dev_labels_b = binarizeY(dev_labels)\n",
      "\n",
      "numClasses = train_labels_b[1].size\n",
      "print 'Classes = %d' %(numClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 4.  4.  4. ...,  4.  6.  7.]\n",
        "Classes = 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We'll start in Theano with implententing logistic regression.  \n",
      "# Recall the four key components: (1) parms, (2) model, (3) cost, and (4) objective. \n",
      "\n",
      "## (1) Parms \n",
      "# Init weights to small, but non-zero, values.\n",
      "#tempweights = np.asarray((np.random.randn(*(numFeatures, numClasses))*.001))\n",
      "#add 1 to classes for the nonexistant 0th class\n",
      "#weights = np.zeros((numFeatures, numClasses+1))\n",
      "#weights[:,1:]=tempweights\n",
      "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.001)))\n",
      "\n",
      "## (2) Model\n",
      "# Theano objects accessed with standard Python variables\n",
      "X = T.fmatrix()\n",
      "Y = T.fmatrix()\n",
      "# Two things to note here.\n",
      "# First, logistic regression can be thought of as a neural net with no hidden layers.  So the output values are \n",
      "# just the dot product of the inputs and the edge weights.\n",
      "# Second, we have 10 classes.  So we can either train separate 1 vs all classification using sigmoid activation, \n",
      "# which would be a hassle, or we can use the softmax activation, which is essentially a multi-class version of sigmoid. \n",
      "def model(X, w):\n",
      "    return T.nnet.softmax(T.dot(X, w))\n",
      "y_hat = model(X, w)\n",
      "\n",
      "\n",
      "## (3) Cost\n",
      "# Cross entropy only considers the error between the true class and the prediction, and not the errors for the false \n",
      "# classes.  This tends to cause the network to converge faster.\n",
      "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
      "\n",
      "\n",
      "## (4) Objective\n",
      "# Minimization using gradient descent.\n",
      "alpha = 0.5\n",
      "gradient = T.grad(cost=cost, wrt=w)\n",
      "update = [[w, w - gradient * alpha]] \n",
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) # computes cost, then runs update\n",
      "y_pred = T.argmax(y_hat, axis=1) # select largest probability as prediction\n",
      "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
      "\n",
      "\n",
      "def gradientDescent(epochs):\n",
      "    trainTime = 0.0\n",
      "    predictTime = 0.0\n",
      "    for i in range(epochs):\n",
      "        start_time = time.time()\n",
      "        cost = train(train_data[0:len(train_data)], train_labels_b[0:len(train_data)])\n",
      "        trainTime =  trainTime + (time.time() - start_time)\n",
      "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(dev_labels_b, axis=1) == predict(dev_data)))\n",
      "    print 'train time = %.2f' %(trainTime)\n",
      "\n",
      "gradientDescent(10)\n",
      "\n",
      "start_time = time.time()\n",
      "predict(dev_data)   \n",
      "print 'predict time = %.5f' %(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1) accuracy = 0.1339\n",
        "2) accuracy = 0.1485\n",
        "3) accuracy = 0.1485\n",
        "4) accuracy = 0.1485\n",
        "5) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6) accuracy = 0.1485\n",
        "7) accuracy = 0.1485\n",
        "8) accuracy = 0.1485\n",
        "9) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10) accuracy = 0.1485\n",
        "train time = 0.13\n",
        "predict time = 0.00127\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Let's switch to SGD and observe the impact. \n",
      "\n",
      "## (1) Parms\n",
      "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))\n",
      "\n",
      "## (2) Model\n",
      "X = T.fmatrix()\n",
      "Y = T.fmatrix()\n",
      "def model(X, w):\n",
      "    return T.nnet.softmax(T.dot(X, w))\n",
      "y_hat = model(X, w)\n",
      "\n",
      "## (3) Cost\n",
      "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
      "\n",
      "## (4) Objective\n",
      "alpha = 0.01\n",
      "gradient = T.grad(cost=cost, wrt=w)\n",
      "update = [[w, w - gradient * alpha]] \n",
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) \n",
      "y_pred = T.argmax(y_hat, axis=1) \n",
      "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
      "\n",
      "## Play with this value and notice the impact.\n",
      "miniBatchSize = 5\n",
      "def gradientDescentStochastic(epochs):\n",
      "    trainTime = 0.0\n",
      "    predictTime = 0.0\n",
      "    start_time = time.time()\n",
      "    for i in range(epochs):       \n",
      "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
      "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
      "        trainTime =  trainTime + (time.time() - start_time)\n",
      "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(dev_labels_b, axis=1) == predict(dev_data)))     \n",
      "    print 'train time = %.2f' %(trainTime)\n",
      "    \n",
      "gradientDescentStochastic(15)\n",
      "\n",
      "start_time = time.time()\n",
      "predict(dev_data)   \n",
      "print 'predict time = %.2f' %(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1) accuracy = 0.1485\n",
        "2) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15) accuracy = 0.1485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train time = 23.20\n",
        "predict time = 0.00\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Now let's add a hidden layer (two layer neural net).\n",
      "\n",
      "## (1) Parms\n",
      "# Try playing with this value.\n",
      "numHiddenNodes = 10\n",
      "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
      "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
      "params = [w_1, w_2]\n",
      "\n",
      "\n",
      "## (2) Model\n",
      "X = T.fmatrix()\n",
      "Y = T.fmatrix()\n",
      "# Two notes:\n",
      "# First, feed forward is the composition of layers (dot product + activation function)\n",
      "# Second, activation on the hidden layer still uses sigmoid\n",
      "def model(X, w_1, w_2):\n",
      "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2))\n",
      "y_hat = model(X, w_1, w_2)\n",
      "\n",
      "\n",
      "## (3) Cost...same as logistic regression\n",
      "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
      "\n",
      "\n",
      "## (4) Minimization.  Update rule changes to backpropagation.\n",
      "alpha = 0.01\n",
      "def backprop(cost, w):\n",
      "    grads = T.grad(cost=cost, wrt=w)\n",
      "    updates = []\n",
      "    for w1, grad in zip(w, grads):\n",
      "        updates.append([w1, w1 - grad * alpha])\n",
      "    return updates\n",
      "update = backprop(cost, params)\n",
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
      "y_pred = T.argmax(y_hat, axis=1)\n",
      "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
      "\n",
      "miniBatchSize = 1 \n",
      "def gradientDescentStochastic(epochs):\n",
      "    trainTime = 0.0\n",
      "    predictTime = 0.0\n",
      "    start_time = time.time()\n",
      "    for i in range(epochs):\n",
      "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
      "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
      "        trainTime =  trainTime + (time.time() - start_time)\n",
      "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(dev_labels_b, axis=1) == predict(dev_data)))\n",
      "    print 'train time = %.2f' %(trainTime)\n",
      "\n",
      "gradientDescentStochastic(10)\n",
      "\n",
      "start_time = time.time()\n",
      "predict(dev_data)   \n",
      "print 'predict time = %.2f' %(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1) accuracy = 0.1343\n",
        "2) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train time = 56.02\n",
        "predict time = 0.00\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## A curiousity: what happens if we simply add a third layer?\n",
      "\n",
      "## (1) Parms\n",
      "numHiddenNodes = 50 \n",
      "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
      "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numHiddenNodes))*.01)))\n",
      "w_3 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
      "params = [w_1, w_2, w_3]\n",
      "\n",
      "## (2) Model\n",
      "X = T.fmatrix()\n",
      "Y = T.fmatrix()\n",
      "def model(X, w_1, w_2, w_3):\n",
      "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2)), w_3))\n",
      "y_hat = model(X, w_1, w_2, w_3)\n",
      "\n",
      "\n",
      "## (3) Cost...same as logistic regression\n",
      "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
      "\n",
      "\n",
      "## (4) Minimization.  Update rule changes to backpropagation.\n",
      "alpha = 0.01\n",
      "def backprop(cost, w):\n",
      "    grads = T.grad(cost=cost, wrt=w)\n",
      "    updates = []\n",
      "    for w1, grad in zip(w, grads):\n",
      "        updates.append([w1, w1 - grad * alpha])\n",
      "    return updates\n",
      "update = backprop(cost, params)\n",
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
      "y_pred = T.argmax(y_hat, axis=1)\n",
      "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
      "\n",
      "miniBatchSize = 1 \n",
      "def gradientDescentStochastic(epochs):\n",
      "    trainTime = 0.0\n",
      "    predictTime = 0.0\n",
      "    start_time = time.time()\n",
      "    for i in range(epochs):\n",
      "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
      "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
      "        trainTime =  trainTime + (time.time() - start_time)\n",
      "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(dev_labels_b, axis=1) == predict(dev_data)))\n",
      "    print 'train time = %.2f' %(trainTime)\n",
      "\n",
      "gradientDescentStochastic(10)\n",
      "\n",
      "start_time = time.time()\n",
      "predict(dev_data)   \n",
      "print 'predict time = %.2f' %(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1) accuracy = 0.1343\n",
        "2) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10) accuracy = 0.1343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train time = 74.15\n",
        "predict time = 0.01\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2-layer NN with rectify activation on the hidden layer.\n",
      "\n",
      "## (1) Parms\n",
      "numHiddenNodes = 400 \n",
      "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
      "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
      "params = [w_1, w_2]\n",
      "\n",
      "## (2) Model\n",
      "X = T.fmatrix()\n",
      "Y = T.fmatrix()\n",
      "\n",
      "def model(X, w_1, w_2):\n",
      "    return T.nnet.softmax(T.dot(T.maximum(T.dot(X, w_1), 0.), w_2))\n",
      "y_hat = model(X, w_1, w_2)\n",
      "\n",
      "\n",
      "## (3) Cost...same as logistic regression\n",
      "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
      "\n",
      "\n",
      "## (4) Minimization.  Update rule changes to backpropagation.\n",
      "alpha = 0.01\n",
      "def backprop(cost, w):\n",
      "    grads = T.grad(cost=cost, wrt=w)\n",
      "    updates = []\n",
      "    for w1, grad in zip(w, grads):\n",
      "        updates.append([w1, w1 - grad * alpha])\n",
      "    return updates\n",
      "update = backprop(cost, params)\n",
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
      "y_pred = T.argmax(y_hat, axis=1)\n",
      "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
      "\n",
      "miniBatchSize = 1 \n",
      "def gradientDescentStochastic(epochs):\n",
      "    trainTime = 0.0\n",
      "    predictTime = 0.0\n",
      "    start_time = time.time()\n",
      "    for i in range(epochs):\n",
      "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
      "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
      "        trainTime =  trainTime + (time.time() - start_time)\n",
      "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(dev_labels_b, axis=1) == predict(test_data)))\n",
      "    print 'train time = %.2f' %(trainTime)\n",
      "\n",
      "gradientDescentStochastic(10)\n",
      "\n",
      "start_time = time.time()\n",
      "predict(test_data)   \n",
      "print 'predict time = %.2f' %(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "shapes (565892,55) and (54,400) not aligned: 55 (dim 1) != 54 (dim 0)\nApply node that caused the error: dot(<TensorType(float32, matrix)>, <TensorType(float64, matrix)>)\nInputs shapes: [(565892, 55), (54, 400)]\nInputs strides: [(220, 4), (3200, 8)]\nInputs types: [TensorType(float32, matrix), TensorType(float64, matrix)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-71-a70e002d91a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'train time = %.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mgradientDescentStochastic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-71-a70e002d91a8>\u001b[0m in \u001b[0;36mgradientDescentStochastic\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtrainTime\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrainTime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'%d) accuracy = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'train time = %.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                     \u001b[0;31m# For the CVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     gof.vm.raise_with_op(self.fn.nodes[self.fn.position_of_error],\n\u001b[0;32m--> 588\u001b[0;31m                                          self.fn.thunks[self.fn.position_of_error])\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;31m# For the c linker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   4550\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4551\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4552\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: shapes (565892,55) and (54,400) not aligned: 55 (dim 1) != 54 (dim 0)\nApply node that caused the error: dot(<TensorType(float32, matrix)>, <TensorType(float64, matrix)>)\nInputs shapes: [(565892, 55), (54, 400)]\nInputs strides: [(220, 4), (3200, 8)]\nInputs types: [TensorType(float32, matrix), TensorType(float64, matrix)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node."
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}